{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNB4No0gkjsn9qXxzKFeA+4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DongUk-Park/RnD/blob/main/POI/NAIS/DataPreprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz02jHReVQp3",
        "outputId": "a03ec763-30f8-4084-8bbd-ac70437656be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "0IoUIsssa0xJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Untils"
      ],
      "metadata": {
        "id": "nKfI4m3viN0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAW Data 생성"
      ],
      "metadata": {
        "id": "PhCUVteFhzfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check_in Data 생성\n",
        "리뷰 데이터로 체크인 데이터를 만든다 <br>\n",
        "원하는 데이터 정보 추가,삭제 : 13, 21 수정"
      ],
      "metadata": {
        "id": "-xyzMoULh3MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 파일 경로\n",
        "json_file_path = '/content/drive/MyDrive/dataset/yelp_dataset/review.json'\n",
        "\n",
        "# CSV 파일 경로\n",
        "csv_file_path = '/content/checkin.csv'\n",
        "\n",
        "# CSV 파일을 쓰기 모드로 열기\n",
        "with open(csv_file_path, 'w', newline='') as csv_file:\n",
        "    # CSV 라이터 생성\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "\n",
        "    # CSV 파일 헤더 작성\n",
        "    csv_writer.writerow(['user_id', 'business_id'])\n",
        "\n",
        "    # JSON 파일을 한 줄씩 읽어서 처리\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
        "        for line in json_file:\n",
        "            data = json.loads(line)  # JSON 데이터 파싱\n",
        "\n",
        "            # user_id와 business_id 추출\n",
        "            user_id = data['user_id']\n",
        "            business_id = data['business_id']\n",
        "\n",
        "            # CSV 파일에 데이터 작성\n",
        "            csv_writer.writerow([user_id, business_id])\n",
        "\n",
        "print(\"checkin_data 생성 완료.\")\n"
      ],
      "metadata": {
        "id": "b7ADsbxTYIeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfad6f00-b3af-493e-9f94-40e8cef59eff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkin_data 생성 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "데이터 개수(row 수) 확인\n",
        "\"\"\"\n",
        "\n",
        "# CSV 파일 경로\n",
        "csv_file_path = '/content/checkin.csv'\n",
        "\n",
        "row_count = 0\n",
        "\n",
        "# CSV 파일을 읽기 모드로 열고 행 수를 센다\n",
        "with open(csv_file_path, 'r', newline='') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    next(csv_reader)  # 헤더 행을 건너뜁니다.\n",
        "    for row in csv_reader:\n",
        "        row_count += 1\n",
        "\n",
        "print(f\"CSV 파일의 행 수: {row_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oN8U_Jwhc-4",
        "outputId": "08d4388d-2298-43fc-893b-2418c5caafa5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV 파일의 행 수: 6990280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Business_info Data 생성\n",
        "Business 데이터로 가게의 위치를 담은 데이터를 만든다 <br>\n",
        "원하는 데이터 정보 추가,삭제 : 13, 21 수정"
      ],
      "metadata": {
        "id": "0xggQlipiDwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 파일 경로\n",
        "json_file_path = '/content/drive/MyDrive/dataset/yelp_dataset/business.json'\n",
        "\n",
        "# CSV 파일 경로\n",
        "csv_file_path = '/content/business_info.csv'\n",
        "\n",
        "# CSV 파일을 쓰기 모드로 열기\n",
        "with open(csv_file_path, 'w', newline='') as csv_file:\n",
        "    # CSV 라이터 생성\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "\n",
        "    # CSV 파일 헤더 작성\n",
        "    csv_writer.writerow(['business_id_num','business_id','latitude ','longitute', 'city'])\n",
        "\n",
        "    # business_id 를 int형으로 변환\n",
        "    idx = 0\n",
        "\n",
        "    # JSON 파일을 한 줄씩 읽어서 처리\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
        "        for line in json_file:\n",
        "            data = json.loads(line)  # JSON 데이터 파싱\n",
        "\n",
        "            # user_id와 business_id 추출\n",
        "            business_id_num = idx\n",
        "            business_id = data['business_id']\n",
        "            latitude = data['latitude']\n",
        "            longitude = data['longitude']\n",
        "            city = data['city']\n",
        "\n",
        "            # CSV 파일에 데이터 작성\n",
        "            csv_writer.writerow([business_id_num, business_id, latitude, longitude, city])\n",
        "            idx += 1\n",
        "\n",
        "print(\"CSV 파일 생성 완료.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIViQvaZf73o",
        "outputId": "c09daf84-1439-4a5f-bf9a-a1e0370a8804"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV 파일 생성 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "데이터 개수(row 수) 확인\n",
        "\"\"\"\n",
        "# CSV 파일 경로\n",
        "csv_file_path = '/content/business_info.csv'\n",
        "\n",
        "row_count = 0\n",
        "\n",
        "# CSV 파일을 읽기 모드로 열고 행 수를 센다\n",
        "with open(csv_file_path, 'r', newline='') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    next(csv_reader)  # 헤더 행을 건너뜁니다.\n",
        "    for row in csv_reader:\n",
        "        row_count += 1\n",
        "\n",
        "print(f\"CSV 파일의 행 수: {row_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjSb85oPhoEq",
        "outputId": "d7631222-73ea-4c27-c0b8-00515dd0b352"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV 파일의 행 수: 150346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사용자 방문데이터(위치포함) 생성\n",
        "위에서 생성한 데이터 두개를 합친 방문데이터 생성 <br>\n",
        "checkin + business_info => location과 city 확인"
      ],
      "metadata": {
        "id": "jZaAIcKIjdeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# business_info.csv 파일 경로\n",
        "business_info_file = '/content/business_info.csv'\n",
        "\n",
        "# checkin_data.csv 파일 경로\n",
        "checkin_data_file = '/content/checkin.csv'\n",
        "\n",
        "# 새로운 CSV 파일 경로 (결과 저장용)\n",
        "output_file = '/content/checkin_data_in_philadelphia.csv'\n",
        "\n",
        "# business_id를 키로 한 dictionary 생성\n",
        "business_location = {}\n",
        "with open(business_info_file, 'r', newline='') as business_file:\n",
        "    csv_reader = csv.reader(business_file)\n",
        "    next(csv_reader)  # 헤더 행 건너뛰기\n",
        "    for row in csv_reader:\n",
        "        business_id_num, business_id, latitude, longitude, city = row[0], row[1], row[2], row[3], row[4].lower() #city : 소문자로 받음\n",
        "        business_location[business_id] = (business_id_num, latitude, longitude, city)\n",
        "\n",
        "count = 0 # 잘 다 들어갔는지 체크\n",
        "mcount = 0 # 잘 안들어간거 있는지 체크\n",
        "not_phila = 0\n",
        "\n",
        "# 새로운 CSV 파일(output_file : checkin_data_with_location)을 작성하여 business_id, latitude, longitude를 추가\n",
        "with open(checkin_data_file, 'r', newline='') as checkin_file, open(output_file, 'w', newline='') as output_csv:\n",
        "    csv_reader = csv.reader(checkin_file)\n",
        "    csv_writer = csv.writer(output_csv)\n",
        "\n",
        "    # 헤더 행 작성\n",
        "    header = next(csv_reader)\n",
        "    header.extend(['business_id', 'latitude', 'longitude', 'city'])\n",
        "    csv_writer.writerow(header)\n",
        "\n",
        "    for row in csv_reader:\n",
        "        business_id = row[1]\n",
        "        if business_id in business_location:\n",
        "            business_id_num, latitude, longitude, city = business_location[business_id]\n",
        "\n",
        "            # city가 \"philadelphia\"인 경우에만 데이터를 CSV 파일에 작성\n",
        "            if \"phila\" in city: #philadelphia 에서 오타가 존재할 수 있기 때문에 \"phila\"만 검사\n",
        "              row.extend([business_id_num, latitude, longitude, city])\n",
        "              # business_id 열을 제외한 열만 저장\n",
        "              csv_writer.writerow(row[0:1] + row[2:])\n",
        "              count += 1\n",
        "            else:\n",
        "              not_phila += 1\n",
        "        else:\n",
        "            # 해당 business_id가 business_info.csv에 없을 경우, 스킵\n",
        "            mcount += 1\n",
        "            continue\n",
        "\n",
        "print(\"CSV 파일에 위치 정보가 추가되었습니다.\")\n",
        "print(count, mcount, not_phila) #philadelphia, 에러, 다른도시\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BJuWs_UjooF",
        "outputId": "c9c4c01b-e2a7-47c8-8a8c-81b2b78a9bea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV 파일에 위치 정보가 추가되었습니다.\n",
            "968791 0 6021489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "user_id 순으로 정렬"
      ],
      "metadata": {
        "id": "byvRheBB6gdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV 파일 경로\n",
        "input_file = '/content/checkin_data_in_philadelphia.csv'\n",
        "output_file = '/content/checkin_data_final.csv'\n",
        "\n",
        "# CSV 파일을 읽고 데이터를 리스트로 저장\n",
        "data = []\n",
        "with open(input_file, 'r', newline='') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    header = next(csv_reader)  # 헤더 행\n",
        "    data.append(header)\n",
        "    for row in csv_reader:\n",
        "        data.append(row)\n",
        "\n",
        "# user_id를 기준으로 데이터를 정렬\n",
        "data = data[1:] # header행 삭제\n",
        "data.sort(key=lambda x: x[0])  # 여기서 0은 user_id 열을 가리킵니다. 0부터 시작하면 첫 번째 열입니다.\n",
        "\n",
        "# user_id를 정수형으로 변환\n",
        "idx = 0\n",
        "before_user_id = data[0][0]\n",
        "for i in data:\n",
        "  if i[0] == before_user_id:\n",
        "    i[0] = idx\n",
        "  else:\n",
        "    idx += 1\n",
        "    before_user_id = i[0]\n",
        "    i[0] = idx\n",
        "\n",
        "\n",
        "# 정렬된 데이터를 새로운 파일에 저장\n",
        "with open(output_file, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(data)\n",
        "\n",
        "print(\"CSV 파일이 user_id를 기준으로 정렬되었고, 새로운 파일에 저장되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ygQK6Rank3J",
        "outputId": "94076b8b-8aba-4262-d2cb-3638bbd41e66"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV 파일이 user_id를 기준으로 정렬되었고, 새로운 파일에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data))\n",
        "data[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV-HFCkWOLfB",
        "outputId": "964d9570-8e07-4849-8076-65b79b19e548"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "968791\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, '59152', '40.0741872', '-75.2030839', 'philadelphia'],\n",
              " [0, '54304', '39.9544408', '-75.1704266', 'philadelphia'],\n",
              " [1, '24787', '39.94362', '-75.1664573', 'philadelphia'],\n",
              " [1, '89986', '39.9418368', '-75.1538396', 'philadelphia'],\n",
              " [2, '88732', '39.9499567', '-75.1449039', 'philadelphia'],\n",
              " [3, '12269', '39.953333', '-75.156571', 'philadelphia'],\n",
              " [3, '19931', '40.0165748179', '-75.1019701564', 'philadelphia'],\n",
              " [3, '73759', '40.0272326', '-75.0283944', 'philadelphia'],\n",
              " [3, '74622', '39.949742', '-75.160578', 'philadelphia'],\n",
              " [3, '87696', '39.9675198', '-75.13981', 'philadelphia'],\n",
              " [3, '114636', '39.9559497', '-75.1571603', 'philadelphia'],\n",
              " [3, '116240', '39.9048734', '-75.1836541', 'philadelphia'],\n",
              " [3, '147905', '39.9623633', '-75.1407424', 'philadelphia'],\n",
              " [4, '5115', '39.9559288', '-75.1574567', 'philadelphia'],\n",
              " [4, '14410', '39.9480501031', '-75.1469577849', 'philadelphia'],\n",
              " [4, '25084', '39.951903', '-75.161795', 'philadelphia'],\n",
              " [4, '25169', '39.9522798', '-75.1446095', 'philadelphia'],\n",
              " [4, '41292', '39.9495774962', '-75.1503095688', 'philadelphia'],\n",
              " [4, '41954', '39.9507587728', '-75.1438647821', 'philadelphia'],\n",
              " [4, '54520', '39.9486633342', '-75.1483974972', 'philadelphia']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train에 사용될 history 데이터 (2차원 리스트)\n",
        "인덱스 번호 : user_Id\n",
        "인덱스 value(list형식) : 해당 uesr가 방문한 business_id 리스트\n",
        "\"\"\"\n",
        "\n",
        "result = []\n",
        "tmp = []\n",
        "before_user_id = 0\n",
        "for idx, i in enumerate(data):\n",
        "  if i[0] == before_user_id:\n",
        "    tmp.append(i[1])\n",
        "  else:\n",
        "    if len(tmp) >= 10: # 방문 횟수가 10회가 넘는 유저만 append\n",
        "      result.append(tmp)\n",
        "\n",
        "    tmp = []\n",
        "    tmp.append(i[1])\n",
        "    before_user_id += 1\n",
        "\n",
        "  if idx == len(data) - 1:\n",
        "    result.append(tmp)\n",
        "\n",
        "output_file = '/content/history_list.csv'\n",
        "with open(output_file, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(result)"
      ],
      "metadata": {
        "id": "E2NI2LS8oEY2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(result))\n",
        "result[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX-RJNJFOqWN",
        "outputId": "9388e10e-cba2-44ef-c152-eb88f44582b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15934\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['5115',\n",
              "  '14410',\n",
              "  '25084',\n",
              "  '25169',\n",
              "  '41292',\n",
              "  '41954',\n",
              "  '54520',\n",
              "  '57245',\n",
              "  '50952',\n",
              "  '51010',\n",
              "  '73288',\n",
              "  '66506',\n",
              "  '80270',\n",
              "  '89703',\n",
              "  '102262',\n",
              "  '130645',\n",
              "  '125933'],\n",
              " ['10607',\n",
              "  '12119',\n",
              "  '35607',\n",
              "  '43918',\n",
              "  '43918',\n",
              "  '52376',\n",
              "  '54929',\n",
              "  '52172',\n",
              "  '46738',\n",
              "  '54505',\n",
              "  '69708',\n",
              "  '87384',\n",
              "  '76931',\n",
              "  '93356',\n",
              "  '125684',\n",
              "  '132288',\n",
              "  '131674',\n",
              "  '137923'],\n",
              " ['8243',\n",
              "  '5382',\n",
              "  '28028',\n",
              "  '19122',\n",
              "  '22587',\n",
              "  '41292',\n",
              "  '56607',\n",
              "  '55231',\n",
              "  '67281',\n",
              "  '71720',\n",
              "  '78574',\n",
              "  '110765',\n",
              "  '110765',\n",
              "  '124275'],\n",
              " ['44641',\n",
              "  '49037',\n",
              "  '59859',\n",
              "  '74667',\n",
              "  '76071',\n",
              "  '98379',\n",
              "  '93403',\n",
              "  '116495',\n",
              "  '116495',\n",
              "  '123342',\n",
              "  '149657',\n",
              "  '144176'],\n",
              " ['29247',\n",
              "  '22046',\n",
              "  '36356',\n",
              "  '45251',\n",
              "  '61025',\n",
              "  '105162',\n",
              "  '94759',\n",
              "  '115314',\n",
              "  '141145',\n",
              "  '138697',\n",
              "  '141945']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test,Validation,Train Data 생성"
      ],
      "metadata": {
        "id": "TzgNb3_5Rklv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "위 history_list를 train, validation, test 데이터셋으로 분리시킴\n",
        "\"\"\"\n",
        "\n",
        "train_ratio = 0.6\n",
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "\n",
        "train_dataset = []\n",
        "test_dataset = []\n",
        "validation_dataset = []\n",
        "\n",
        "train_negative_dataset = [] # business_id 개수 : 150346개\n",
        "validation_negative_dataset = []\n",
        "test_negative_dataset = []\n",
        "\n",
        "\n",
        "#아래의 결과를 csv 파일로 저장할 경로, 총 6개의 파일 생성\n",
        "output_train = '/content/history_train.csv'\n",
        "output_validation = '/content/history_validation.csv'\n",
        "output_test = '/content/history_test.csv'\n",
        "\n",
        "output_train_negative = '/content/history_negative_train.csv'\n",
        "output_validation_negative = '/content/history_negative_validation.csv'\n",
        "output_test_negative = '/content/history_negative_test.csv'\n",
        "\n",
        "for user, history in enumerate(result):\n",
        "  ### 한 유저에 대해 train,validation,test dataset 생성\n",
        "  total_samples = len(history) # 방문 횟수 저장\n",
        "  random.shuffle(history) # 방문 기록 순서를 랜덤하게 섞어준다.\n",
        "\n",
        "  train_size = int(total_samples * train_ratio)\n",
        "  validation_size = int(total_samples * validation_ratio)\n",
        "\n",
        "  list_train = history[:train_size]\n",
        "  list_validation = history[train_size: (train_size + validation_size)]\n",
        "  list_test = history[(train_size + validation_size):]\n",
        "\n",
        "  train_dataset.append(list_train)\n",
        "  validation_dataset.append(list_validation)\n",
        "  test_dataset.append(list_test)\n",
        "\n",
        "  ### 한 유저에 대한 negative dataset 생성\n",
        "  neg_train = []\n",
        "  neg_val = []\n",
        "  neg_test = []\n",
        "  for i in range(150346): # business_id 개수만큼 반복\n",
        "    if i in list_train:\n",
        "      continue\n",
        "    else:\n",
        "      neg_train.append(i)\n",
        "    if i in list_validation:\n",
        "      continue\n",
        "    else:\n",
        "      neg_val.append(i)\n",
        "    if i in list_test:\n",
        "      continue\n",
        "    else:\n",
        "      neg_test.append(i)\n",
        "\n",
        "\n",
        "  with open(output_train_negative, 'w', newline='') as csv_file:\n",
        "      csv_writer = csv.writer(csv_file)\n",
        "      csv_writer.writerow(neg_train)\n",
        "  with open(output_validation_negative, 'w', newline='') as csv_file:\n",
        "      csv_writer = csv.writer(csv_file)\n",
        "      csv_writer.writerow(neg_val)\n",
        "  with open(output_test_negative, 'w', newline='') as csv_file:\n",
        "      csv_writer = csv.writer(csv_file)\n",
        "      csv_writer.writerow(neg_test)\n",
        "\n",
        "\n",
        "# print(len(train_dataset), train_dataset[:5])\n",
        "# print(len(validation_dataset), validation_dataset[:5])\n",
        "# print(len(test_dataset), test_dataset[:5])\n",
        "\n",
        "\n",
        "# print(len(train_negative_dataset), train_negative_dataset[:5])\n",
        "# print(len(validation_negative_dataset), validation_negative_dataset[:5])\n",
        "# print(len(test_negative_dataset), test_negative_dataset[:5])\n",
        "\n",
        "\n",
        "\n",
        "with open(output_train, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(train_dataset)\n",
        "with open(output_validation, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(validation_dataset)\n",
        "with open(output_test, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(test_dataset)\n"
      ],
      "metadata": {
        "id": "auxgWqTXVJDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        ""
      ],
      "metadata": {
        "id": "RPDlhI-jYzsZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}