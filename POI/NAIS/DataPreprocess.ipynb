{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO8tzrDrqeTTkmcneP/tcKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DongUk-Park/RnD/blob/main/POI/NAIS/DataPreprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz02jHReVQp3",
        "outputId": "4aba7b6d-628e-4efd-dd59-821fbd5d2905"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "0IoUIsssa0xJ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Untils"
      ],
      "metadata": {
        "id": "nKfI4m3viN0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAW Data 생성"
      ],
      "metadata": {
        "id": "PhCUVteFhzfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check_in Data 생성\n",
        "리뷰 데이터로 체크인 데이터(user,business_id)를 만든다 <br>\n",
        "원하는 데이터 정보 추가,삭제 : 13, 21 수정"
      ],
      "metadata": {
        "id": "-xyzMoULh3MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 파일 경로\n",
        "json_file_path = '/content/drive/MyDrive/dataset/yelp_dataset/review.json'\n",
        "\n",
        "# CSV 파일 경로\n",
        "csv_file_path = '/content/checkin.csv'\n",
        "\n",
        "# CSV 파일을 쓰기 모드로 열기\n",
        "with open(csv_file_path, 'w', newline='') as csv_file:\n",
        "    # CSV 라이터 생성\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "\n",
        "    # CSV 파일 헤더 작성\n",
        "    csv_writer.writerow(['user_id', 'business_id'])\n",
        "\n",
        "    # JSON 파일을 한 줄씩 읽어서 처리\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
        "        for line in json_file:\n",
        "            data = json.loads(line)  # JSON 데이터 파싱\n",
        "\n",
        "            # user_id와 business_id 추출\n",
        "            user_id = data['user_id']\n",
        "            business_id = data['business_id']\n",
        "\n",
        "            # CSV 파일에 데이터 작성\n",
        "            csv_writer.writerow([user_id, business_id])\n",
        "\n",
        "print(\"checkin_data 생성 완료.\")\n"
      ],
      "metadata": {
        "id": "b7ADsbxTYIeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c084ad-06b5-49a7-809d-94b8da1821ad"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkin_data 생성 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "데이터 개수(row 수) 확인\n",
        "\"\"\"\n",
        "\n",
        "# CSV 파일 경로\n",
        "csv_file_path = '/content/checkin.csv'\n",
        "\n",
        "row_count = 0\n",
        "\n",
        "# CSV 파일을 읽기 모드로 열고 행 수를 센다\n",
        "with open(csv_file_path, 'r', newline='') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    next(csv_reader)  # 헤더 행을 건너뜁니다.\n",
        "    for row in csv_reader:\n",
        "        row_count += 1\n",
        "\n",
        "print(f\"CSV 파일의 행 수: {row_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oN8U_Jwhc-4",
        "outputId": "f439e334-2a29-43f9-9760-932fb375e98b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV 파일의 행 수: 6990280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Business_info Data 생성\n",
        "Business 데이터로 가게의 위치를 담은 데이터(business_id,location, city)를 만든다 <br>\n",
        "원하는 데이터 정보 추가,삭제 : 13, 21 수정"
      ],
      "metadata": {
        "id": "0xggQlipiDwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 파일 경로\n",
        "json_file_path = '/content/drive/MyDrive/dataset/yelp_dataset/business.json'\n",
        "\n",
        "# CSV 파일 경로\n",
        "csv_file_path = '/content/business_info.csv'\n",
        "\n",
        "# CSV 파일을 쓰기 모드로 열기\n",
        "with open(csv_file_path, 'w', newline='') as csv_file:\n",
        "    # CSV 라이터 생성\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "\n",
        "    # CSV 파일 헤더 작성\n",
        "    csv_writer.writerow(['business_id_num','business_id','latitude ','longitute', 'city'])\n",
        "\n",
        "    # business_id 를 int형으로 변환\n",
        "    idx = 0\n",
        "\n",
        "    # JSON 파일을 한 줄씩 읽어서 처리\n",
        "    with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
        "        for line in json_file:\n",
        "            data = json.loads(line)  # JSON 데이터 파싱\n",
        "\n",
        "            # user_id와 business_id 추출\n",
        "            business_id_num = idx\n",
        "            business_id = data['business_id']\n",
        "            latitude = data['latitude']\n",
        "            longitude = data['longitude']\n",
        "            city = data['city']\n",
        "\n",
        "            # CSV 파일에 데이터 작성\n",
        "            csv_writer.writerow([business_id_num, business_id, latitude, longitude, city])\n",
        "            idx += 1\n",
        "\n",
        "print(\"CSV 파일 생성 완료.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIViQvaZf73o",
        "outputId": "63bde303-2bb6-4e03-813f-e990cc572a1f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV 파일 생성 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "데이터 개수(row 수) 확인\n",
        "\"\"\"\n",
        "# CSV 파일 경로\n",
        "csv_file_path = '/content/business_info.csv'\n",
        "\n",
        "row_count = 0\n",
        "\n",
        "# CSV 파일을 읽기 모드로 열고 행 수를 센다\n",
        "with open(csv_file_path, 'r', newline='') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    next(csv_reader)  # 헤더 행을 건너뜁니다.\n",
        "    for row in csv_reader:\n",
        "        row_count += 1\n",
        "\n",
        "print(f\"CSV 파일의 행 수: {row_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjSb85oPhoEq",
        "outputId": "7b447d50-c69a-419c-f14c-984a9835df2b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV 파일의 행 수: 150346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "business_info에서 philadelphia에 속한 가게만 남김\n",
        "\"\"\"\n",
        "\n",
        "df = pd.read_csv('/content/business_info.csv')\n",
        "\n",
        "# city 칼럼에서 \"philadelphia\"인 행만 선택\n",
        "filtered_df = df[df['city'].str.contains(\"phila\", case=False, na=False)]\n",
        "\n",
        "# 필터링된 데이터를 CSV 파일로 저장\n",
        "filtered_df.to_csv('/content/business_info_in_philadelphia.csv', index=False)\n",
        "\n",
        "print(\"CSV 파일 필터링 및 저장 완료.\")\n",
        "filtered_df.shape\n",
        "\n",
        "business_id_list = filtered_df['business_id_num'].tolist()\n",
        "print(business_id_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rag7nG7obg6v",
        "outputId": "a1c4826a-562c-409b-a4b5-7d4bd16d33aa"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV 파일 필터링 및 저장 완료.\n",
            "[3, 15, 19, 28, 31]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사용자 방문데이터(위치포함) 생성\n",
        "위에서 생성한 데이터 두개를 합친 방문데이터 생성 <br>\n",
        "checkin + business_info => location과 city 확인<br>\n",
        "Philadelphia 도시에 대한 데이터만 남김"
      ],
      "metadata": {
        "id": "jZaAIcKIjdeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# business_info.csv 파일 경로\n",
        "business_info_file = '/content/business_info.csv'\n",
        "\n",
        "# checkin_data.csv 파일 경로\n",
        "checkin_data_file = '/content/checkin.csv'\n",
        "\n",
        "# 새로운 CSV 파일 경로 (결과 저장용)\n",
        "output_file = '/content/checkin_data_in_philadelphia.csv'\n",
        "\n",
        "# business_id를 키로 한 dictionary 생성\n",
        "business_location = {}\n",
        "with open(business_info_file, 'r', newline='') as business_file:\n",
        "    csv_reader = csv.reader(business_file)\n",
        "    next(csv_reader)  # 헤더 행 건너뛰기\n",
        "    for row in csv_reader:\n",
        "        business_id_num, business_id, latitude, longitude, city = row[0], row[1], row[2], row[3], row[4].lower() #city : 소문자로 받음\n",
        "        business_location[business_id] = (business_id_num, latitude, longitude, city)\n",
        "\n",
        "count = 0 # 잘 다 들어갔는지 체크\n",
        "mcount = 0 # 잘 안들어간거 있는지 체크\n",
        "not_phila = 0\n",
        "\n",
        "# 새로운 CSV 파일(output_file : checkin_data_in_philadelphia)을 작성하여 business_id, latitude, longitude를 추가\n",
        "with open(checkin_data_file, 'r', newline='') as checkin_file, open(output_file, 'w', newline='') as output_csv:\n",
        "    csv_reader = csv.reader(checkin_file)\n",
        "    csv_writer = csv.writer(output_csv)\n",
        "\n",
        "    # 헤더 행 작성\n",
        "    header = next(csv_reader)\n",
        "    header.extend(['business_id', 'latitude', 'longitude', 'city'])\n",
        "    csv_writer.writerow(header)\n",
        "\n",
        "    for row in csv_reader:\n",
        "        business_id = row[1]\n",
        "        if business_id in business_location:\n",
        "            business_id_num, latitude, longitude, city = business_location[business_id]\n",
        "\n",
        "            # city가 \"philadelphia\"인 경우에만 데이터를 CSV 파일에 작성\n",
        "            if \"philadelphia\" in city: #philadelphia 에서 오타가 존재할 수 있기 때문에 \"phila\"만 검사\n",
        "              row.extend([business_id_num, latitude, longitude, city])\n",
        "              # business_id 열을 제외한 열만 저장\n",
        "              csv_writer.writerow(row[0:1] + row[2:])\n",
        "              count += 1\n",
        "            else:\n",
        "              not_phila += 1\n",
        "        else:\n",
        "            # 해당 business_id가 business_info.csv에 없을 경우, 스킵\n",
        "            mcount += 1\n",
        "            continue\n",
        "\n",
        "print(\"CSV 파일에 위치 정보가 추가되었습니다.\")\n",
        "print(count, mcount, not_phila) #philadelphia, 에러, 다른도시\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BJuWs_UjooF",
        "outputId": "1359e48a-3b4a-472d-b1d0-237ab4feba95"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV 파일에 위치 정보가 추가되었습니다.\n",
            "968050 0 6022230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "user_id 순으로 정렬"
      ],
      "metadata": {
        "id": "byvRheBB6gdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV 파일 경로\n",
        "input_file = '/content/checkin_data_in_philadelphia.csv'\n",
        "output_file = '/content/checkin_data_final.csv'\n",
        "\n",
        "# CSV 파일을 읽고 데이터를 리스트로 저장\n",
        "data = []\n",
        "with open(input_file, 'r', newline='') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    header = next(csv_reader)  # 헤더 행\n",
        "    data.append(header)\n",
        "    for row in csv_reader:\n",
        "        data.append(row)\n",
        "\n",
        "# user_id를 기준으로 데이터를 정렬\n",
        "\n",
        "print(data[:3])\n",
        "\n",
        "data = data[1:] # header행 삭제\n",
        "data.sort(key=lambda x: x[0])  # 여기서 0은 user_id 열을 가리킵니다. 0부터 시작하면 첫 번째 열입니다.\n",
        "\n",
        "# user_id를 정수형으로 변환\n",
        "idx = 0\n",
        "before_user_id = data[0][0]\n",
        "for i in data:\n",
        "  if i[0] == before_user_id:\n",
        "    i[0] = idx\n",
        "  else:\n",
        "    idx += 1\n",
        "    before_user_id = i[0]\n",
        "    i[0] = idx\n",
        "\n",
        "\n",
        "# 정렬된 데이터를 새로운 파일에 저장\n",
        "with open(output_file, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(data)\n",
        "\n",
        "print(\"CSV 파일이 user_id를 기준으로 정렬되었고, 새로운 파일에 저장되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ygQK6Rank3J",
        "outputId": "b01b6221-e7c5-405f-b670-323c1f46b85f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['user_id', 'business_id', 'business_id', 'latitude', 'longitude', 'city'], ['OyoGAe7OKpv6SyGZT5g77Q', '12886', '39.9521029', '-75.1727526', 'philadelphia'], ['_7bHUi9Uuf5__HHc_Q8guQ', '6316', '40.0798480557', '-75.025079772', 'philadelphia']]\n",
            "CSV 파일이 user_id를 기준으로 정렬되었고, 새로운 파일에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 확인\n",
        "print(len(data))\n",
        "data[13:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV-HFCkWOLfB",
        "outputId": "5f34edda-41db-4cad-df77-472666947124"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "968050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, '5115', '39.9559288', '-75.1574567', 'philadelphia'],\n",
              " [4, '14410', '39.9480501031', '-75.1469577849', 'philadelphia'],\n",
              " [4, '25084', '39.951903', '-75.161795', 'philadelphia'],\n",
              " [4, '25169', '39.9522798', '-75.1446095', 'philadelphia'],\n",
              " [4, '41292', '39.9495774962', '-75.1503095688', 'philadelphia'],\n",
              " [4, '41954', '39.9507587728', '-75.1438647821', 'philadelphia'],\n",
              " [4, '54520', '39.9486633342', '-75.1483974972', 'philadelphia'],\n",
              " [4, '57245', '39.949042', '-75.149198', 'philadelphia'],\n",
              " [4, '50952', '39.9488186002', '-75.1489040628', 'philadelphia'],\n",
              " [4, '51010', '40.0874923342', '-74.9616227288', 'philadelphia'],\n",
              " [4, '73288', '39.9488980012', '-75.1500296367', 'philadelphia'],\n",
              " [4, '66506', '39.9527511597', '-75.1424942017', 'philadelphia'],\n",
              " [4, '80270', '39.9509761191', '-75.1500126909', 'philadelphia'],\n",
              " [4, '89703', '39.9481737', '-75.1424642', 'philadelphia'],\n",
              " [4, '102262', '39.947326', '-75.147276', 'philadelphia'],\n",
              " [4, '130645', '39.9518574786', '-75.1461736562', 'philadelphia'],\n",
              " [4, '125933', '39.9600237', '-75.1371563', 'philadelphia']]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train에 사용될 history 데이터 (2차원 리스트)\n",
        "인덱스 번호 : user_Id\n",
        "인덱스 value(list형식) : 해당 uesr가 방문한 business_id 리스트\n",
        "\"\"\"\n",
        "\n",
        "history_list = []\n",
        "tmp = []\n",
        "before_user_id = 0\n",
        "for idx, i in enumerate(data):\n",
        "  if i[0] == before_user_id:\n",
        "    tmp.append(i[1])\n",
        "  else:\n",
        "    if len(tmp) >= 10: # 방문 횟수가 10회가 넘는 유저만 append\n",
        "      history_list.append(tmp)\n",
        "\n",
        "    tmp = []\n",
        "    tmp.append(i[1])\n",
        "    before_user_id += 1\n",
        "\n",
        "  if idx == len(data) - 1:\n",
        "    history_list.append(tmp)\n",
        "\n",
        "output_file = '/content/history_list.csv'\n",
        "with open(output_file, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(history_list)"
      ],
      "metadata": {
        "id": "E2NI2LS8oEY2"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(history_list))\n",
        "\n",
        "sum = 0\n",
        "for i in history_list:\n",
        "  sum += len(i)\n",
        "print(sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX-RJNJFOqWN",
        "outputId": "6ff8d1b9-e253-4183-feae-b61e6bfcf9f7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15919\n",
            "465587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test,Validation,Train Data 생성"
      ],
      "metadata": {
        "id": "TzgNb3_5Rklv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "위 history_list를 train, validation, test 데이터셋으로 분리시킴\n",
        "\"\"\"\n",
        "\n",
        "train_ratio = 0.6\n",
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "\n",
        "train_dataset = []\n",
        "test_dataset = []\n",
        "validation_dataset = []\n",
        "\n",
        "train_negative_dataset = [] # business_id 개수 : 150346개\n",
        "validation_negative_dataset = []\n",
        "test_negative_dataset = []\n",
        "\n",
        "\n",
        "#아래의 결과를 csv 파일로 저장할 경로, 총 6개의 파일 생성\n",
        "output_train = '/content/history_train.csv'\n",
        "output_validation = '/content/history_validation.csv'\n",
        "output_test = '/content/history_test.csv'\n",
        "\n",
        "\n",
        "for user, history in enumerate(history_list):\n",
        "  ### 한 유저에 대해 train,validation,test dataset 생성\n",
        "  total_samples = len(history) # 방문 횟수 저장\n",
        "  random.shuffle(history) # 방문 기록 순서를 랜덤하게 섞어준다.\n",
        "\n",
        "  train_size = int(total_samples * train_ratio)\n",
        "  validation_size = int(total_samples * validation_ratio)\n",
        "\n",
        "  list_test = history[(train_size + validation_size):]\n",
        "  list_validation = history[train_size: (train_size + validation_size)]\n",
        "  list_train = history[:train_size]\n",
        "\n",
        "\n",
        "  train_dataset.append(list_train)\n",
        "  validation_dataset.append(list_validation)\n",
        "  test_dataset.append(list_test)\n",
        "\n",
        "# output_train_negative = '/content/history_negative_train.csv'\n",
        "# output_validation_negative = '/content/history_negative_validation.csv'\n",
        "# output_test_negative = '/content/history_negative_test.csv'\n",
        "\n",
        "# with open(output_train_negative, 'w', newline='') as csv_file1:\n",
        "#   with open(output_validation_negative, 'w', newline='') as csv_file2:\n",
        "#     with open(output_test_negative, 'w', newline='') as csv_file3:\n",
        "#       csv_writer1 = csv.writer(csv_file1)\n",
        "#       csv_writer2 = csv.writer(csv_file2)\n",
        "#       csv_writer3 = csv.writer(csv_file3)\n",
        "\n",
        "        # ### 한 유저에 대한 negative dataset 생성\n",
        "        # neg_train = []\n",
        "        # neg_val = []\n",
        "        # neg_test = []\n",
        "        # for i in range(14603): # business_id 개수만큼 반복\n",
        "        #   if i in list_train:\n",
        "        #     continue\n",
        "        #   else:\n",
        "        #     neg_train.append(i)\n",
        "        #   if i in list_validation:\n",
        "        #     continue\n",
        "        #   else:\n",
        "        #     neg_val.append(i)\n",
        "        #   if i in list_test:\n",
        "        #     continue\n",
        "        #   else:\n",
        "        #     neg_test.append(i)\n",
        "        # csv_writer1.writerow(neg_train)\n",
        "        # csv_writer2.writerow(neg_val)\n",
        "        # csv_writer3.writerow(neg_test)\n",
        "\n",
        "with open(output_train, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(train_dataset)\n",
        "with open(output_validation, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(validation_dataset)\n",
        "with open(output_test, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(test_dataset)\n"
      ],
      "metadata": {
        "id": "auxgWqTXVJDk"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset), train_dataset[:5])\n",
        "print(len(validation_dataset), validation_dataset[:5])\n",
        "print(len(test_dataset), test_dataset[:5])\n",
        "\n",
        "\n",
        "# print(len(train_negative_dataset), train_negative_dataset[:5])\n",
        "# print(len(validation_negative_dataset), validation_negative_dataset[:5])\n",
        "# print(len(test_negative_dataset), test_negative_dataset[:5])"
      ],
      "metadata": {
        "id": "RPDlhI-jYzsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bedc21f-2521-45bb-f87a-cd5db8250a8e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15919 [['125933', '66506', '89703', '50952', '14410', '80270', '25169', '25084', '102262', '73288'], ['76931', '125684', '46738', '12119', '54929', '87384', '137923', '43918', '93356', '10607'], ['67281', '28028', '22587', '5382', '124275', '78574', '55231', '71720'], ['116495', '49037', '74667', '123342', '59859', '149657', '93403'], ['45251', '22046', '61025', '141145', '105162', '141945']]\n",
            "15919 [['130645', '57245', '5115'], ['131674', '54505', '35607'], ['19122', '41292'], ['144176', '76071'], ['94759', '29247']]\n",
            "15919 [['51010', '41954', '54520', '41292'], ['52172', '69708', '52376', '43918', '132288'], ['56607', '110765', '110765', '8243'], ['98379', '44641', '116495'], ['115314', '138697', '36356']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 지역 임베딩 데이터 생성\n",
        "NAIS 코드 완성 이후 진행 예정"
      ],
      "metadata": {
        "id": "yN8a162TTNsf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CC2g2o5rTRAf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}