{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPybecdZyDpHUCciB2hZ5sQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DongUk-Park/RnD/blob/main/POI/NAIS/Foursquare_DataPreprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import random"
      ],
      "metadata": {
        "id": "6fFMAuS81v3w"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYrGl8PtyL4J",
        "outputId": "ea90bbcf-b3b8-4906-cd71-8fd1c0626ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         user_id  business_id    Time_stamp\n",
            "0              0            0  1.333447e+09\n",
            "1              1            1  1.333447e+09\n",
            "2              2            2  1.333447e+09\n",
            "3              3            3  1.333447e+09\n",
            "4              4            4  1.333447e+09\n",
            "...          ...          ...           ...\n",
            "1196243    23986         4137  1.379345e+09\n",
            "1196244    10425         6898  1.379345e+09\n",
            "1196245    13985        26509  1.379345e+09\n",
            "1196246      131         2205  1.379345e+09\n",
            "1196247     6792        26144  1.379345e+09\n",
            "\n",
            "[1196248 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# 파일 경로\n",
        "file_path = 'Foursquare_checkins.txt'\n",
        "\n",
        "# 파일 읽어오기\n",
        "df = pd.read_csv(file_path, sep='\\t', header=None, names=['user_id', 'business_id', 'Time_stamp'])\n",
        "# 'Time_stamp' 열 삭제\n",
        "print(df)\n",
        "df.drop('Time_stamp', axis=1, inplace=True)\n",
        "data = df.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train에 사용될 history 데이터 (2차원 리스트)\n",
        "인덱스 번호 : user_Id\n",
        "인덱스 value(list형식) : 해당 uesr가 방문한 business_id 리스트\n",
        "\"\"\"\n",
        "\n",
        "data.sort(key=lambda x: x[0])\n",
        "\n",
        "history_list = []\n",
        "tmp = []\n",
        "before_user_id = 0\n",
        "for idx, i in enumerate(data):\n",
        "  if i[0] == before_user_id:\n",
        "    tmp.append(i[1])\n",
        "  else:\n",
        "    tmp = list(dict.fromkeys(tmp)) # dictionary key 특성을 이용한 중복제거\n",
        "    if len(tmp) >= 10: # 중복이 제거된 방문 횟수가 10회가 넘는 유저만 append\n",
        "      history_list.append(tmp)\n",
        "\n",
        "    tmp = []\n",
        "    tmp.append(i[1])\n",
        "    before_user_id += 1\n",
        "\n",
        "  if idx == len(data) - 1:\n",
        "    if len(tmp) >= 10:\n",
        "      history_list.append(tmp)\n",
        "\n",
        "output_file = '/content/history_list.csv'\n",
        "with open(output_file, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(history_list)"
      ],
      "metadata": {
        "id": "CUIbATohz7aY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(history_list))\n",
        "print(history_list[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvZ07gPi2vy9",
        "outputId": "4f7b4175-55c4-4c42-c608-ffccd553198e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24941\n",
            "[[0, 249, 1323, 10155, 3093, 3316, 1449, 13890, 336, 4226, 163, 4684, 348, 3438, 19553, 7220, 6476, 21614, 7784, 98, 1018, 16557, 21960, 15744, 13610], [1, 1684, 1705, 1868, 2452, 1742, 4941, 5727, 8525, 6892, 9176, 1607, 9189, 9190, 1812, 9191, 3882, 740, 3989, 11873, 8153, 11880, 11881, 11884, 887, 3484, 13052, 2239, 2663, 17112, 17071, 1254, 3451, 21098, 1776, 3478, 21108, 21110, 1525, 18389, 21171, 21177, 18392, 21380, 21266, 21253, 21182, 21331, 21336, 21279, 21289, 21286, 21386, 21358, 21375, 21262, 21382, 21264, 21302, 19141, 21431, 684, 1475, 75, 13935, 4114, 4645, 3504, 9927, 14858, 19073, 12689, 5133, 2466]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "business_info = pd.read_csv('/content/Foursquare_poi_coos.txt', sep='\\t', header=None, names = ['business_id','latitude','longitude'])\n",
        "print(business_info)\n",
        "business_id_list = business_info['business_id'].tolist()\n",
        "latitude_list = business_info['latitude'].tolist()\n",
        "longitude_list = business_info['longitude'].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR8kNTdI19nn",
        "outputId": "ddbba189-a6bd-44cb-e264-a8a10e2e9add"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       business_id   latitude   longitude\n",
            "0                0  40.748939  -73.992280\n",
            "1                1  40.719726  -74.002472\n",
            "2                2  25.696201 -100.351632\n",
            "3                3  41.875497  -87.649484\n",
            "4                4  40.443403  -79.954869\n",
            "...            ...        ...         ...\n",
            "28588        28588  33.761346  -84.386458\n",
            "28589        28589  39.963072  -75.176862\n",
            "28590        28590  47.621870 -122.351738\n",
            "28591        28591  40.772144  -73.984377\n",
            "28592        28592  41.902165  -87.704329\n",
            "\n",
            "[28593 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "위 history_list를 train, validation, test 데이터셋으로 분리시킴\n",
        "\"\"\"\n",
        "train_ratio = 0.6\n",
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "\n",
        "train_dataset = []\n",
        "test_dataset = []\n",
        "validation_dataset = []\n",
        "\n",
        "train_negative_dataset = []\n",
        "test_negative_dataset = []\n",
        "validation_negative_dataset = []\n",
        "\n",
        "\n",
        "#아래의 결과를 csv 파일로 저장할 경로, 총 6개의 파일 생성\n",
        "output_train = '/content/history_train.csv'\n",
        "output_validation = '/content/history_validation.csv'\n",
        "output_test = '/content/history_test.csv'\n",
        "\n",
        "output_train_negative = '/content/history_train_negative.csv'\n",
        "output_validation_negative = '/content/history_validation_negative.csv'\n",
        "output_test_negative = '/content/history_test_negative.csv'\n",
        "\n",
        "\n",
        "for user, history in enumerate(history_list):\n",
        "  negative_list = [num for num in business_id_list if num not in history]\n",
        "\n",
        "  ### 한 유저에 대해 train,validation,test dataset 생성\n",
        "  total_samples = len(history) # 방문 횟수 저장\n",
        "  random.shuffle(history) # 방문 기록 순서를 랜덤하게 섞어준다.\n",
        "\n",
        "  train_size = int(total_samples * train_ratio)\n",
        "  validation_size = int(total_samples * validation_ratio)\n",
        "\n",
        "  list_train = history[:train_size]\n",
        "  list_validation = history[train_size: (train_size + validation_size)]\n",
        "  list_test = history[(train_size + validation_size):]\n",
        "\n",
        "\n",
        "  train_dataset.append(list_train)\n",
        "  validation_dataset.append(list_validation)\n",
        "  test_dataset.append(list_test)\n",
        "\n",
        "  total_samples = len(negative_list) # 방문 횟수 저장\n",
        "  random.shuffle(negative_list) # 방문 기록 순서를 랜덤하게 섞어준다.\n",
        "\n",
        "  train_size = int(total_samples * train_ratio)\n",
        "  validation_size = int(total_samples * validation_ratio)\n",
        "\n",
        "  negative_list_train = negative_list[:train_size]\n",
        "  negative_list_validation = negative_list[train_size: (train_size + validation_size)]\n",
        "  negative_list_test = negative_list[(train_size + validation_size):]\n",
        "\n",
        "  train_negative_dataset.append(negative_list_train)\n",
        "  validation_negative_dataset.append(negative_list_validation)\n",
        "  test_negative_dataset.append(negative_list_test)\n",
        "\n",
        "with open(output_train, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(train_dataset)\n",
        "with open(output_validation, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(validation_dataset)\n",
        "with open(output_test, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(test_dataset)\n",
        "\n",
        "with open(output_train_negative, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(train_negative_dataset)\n",
        "with open(output_validation_negative, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(validation_negative_dataset)\n",
        "with open(output_test_negative, 'w', newline='') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "    csv_writer.writerows(test_negative_dataset)"
      ],
      "metadata": {
        "id": "PPSc6Ymz13nb"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}