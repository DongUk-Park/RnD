{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DongUk-Park/RnD/blob/main/POI/NAIS/MF_BPR_POI_distance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGRKWFXygTnz"
      },
      "source": [
        "#Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM0y8Lx95Sh7",
        "outputId": "7fd20c01-c780-4222-9aa1-5fbad5030583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ekiUZ2kgvKh-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import random\n",
        "import csv\n",
        "import copy\n",
        "\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.backends.cudnn as cudnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8LIZjtzmdW9"
      },
      "source": [
        "# Data Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load_data"
      ],
      "metadata": {
        "id": "e_yud6w4IFdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  train_dataset_path = '/content/history_train.csv'\n",
        "  validation_dataset_path = '/content/history_validation.csv'\n",
        "  test_dataset_path = '/content/history_test.csv'\n",
        "\n",
        "  train_history_data = []\n",
        "  validation_history_data = []\n",
        "  test_history_data = []\n",
        "\n",
        "  with open(train_dataset_path, 'r', newline='') as csv_train:\n",
        "      csv_reader = csv.reader(csv_train)\n",
        "      header = next(csv_reader)  # 헤더 행, 실제론 data 바로 들어옴\n",
        "      header = [int(item) for item in header]\n",
        "      train_history_data.append(header)\n",
        "      for row in csv_reader:\n",
        "          r = [int(item) for item in row]\n",
        "          train_history_data.append(r)\n",
        "\n",
        "  with open(validation_dataset_path, 'r', newline='') as csv_validation:\n",
        "      csv_reader = csv.reader(csv_validation)\n",
        "      header = next(csv_reader)  # 헤더 행, 실제론 data 바로 들어옴\n",
        "      header = [int(item) for item in header]\n",
        "      validation_history_data.append(header)\n",
        "      for row in csv_reader:\n",
        "          r = [int(item) for item in row]\n",
        "          validation_history_data.append(r)\n",
        "\n",
        "  with open(test_dataset_path, 'r', newline='') as csv_test:\n",
        "      csv_reader = csv.reader(csv_test)\n",
        "      header = next(csv_reader)  # 헤더 행, 실제론 data 바로 들어옴\n",
        "      header = [int(item) for item in header]\n",
        "      test_history_data.append(header)\n",
        "      for row in csv_reader:\n",
        "          r = [int(item) for item in row]\n",
        "          test_history_data.append(r)\n",
        "\n",
        "  num_users = len(train_history_data) # 필라델피아의 사용자 수 : 15359명\n",
        "  num_items = business_id_info.shape[0] # 필라델피아의 가게 수 : 14586개, 0 ~ 14585\n",
        "\n",
        "  negative_train_history_data = []\n",
        "  negative_validation_history_data = []\n",
        "  negative_test_history_data = []\n",
        "\n",
        "  with open('/content/history_train_negative.csv', 'r', newline='') as ng_train, open('/content/history_test_negative.csv', 'r', newline='') as ng_test:\n",
        "      ng_train_reader = csv.reader(ng_train)\n",
        "      ng_test_reader = csv.reader(ng_test)\n",
        "      for row in ng_train_reader:\n",
        "        r = [int(item) for item in row]\n",
        "        negative_train_history_data.append(r)\n",
        "      for row in ng_test_reader:\n",
        "        r =  [int(item) for item in row]\n",
        "        negative_test_history_data.append(r)\n",
        "\n",
        "  target_idx_list = copy.deepcopy(test_history_data)\n",
        "  for i in range(num_users):\n",
        "    target_idx_list[i].extend(negative_test_history_data[i])\n",
        "\n",
        "  business_id_info = pd.read_csv('/content/business_info_in_philadelphia.csv', names = ['business_id', 'latitude', 'longitude', 'city'])\n",
        "  item_list = business_id_info['business_id'].tolist()\n",
        "  latitude_list = business_id_info['latitude'].tolist()\n",
        "  longitude_list = business_id_info['longitude'].tolist()\n",
        "\n",
        "\n",
        "  return item_list, latitude_list, longitude_list, num_users, num_items, train_history_data, validation_history_data, test_history_data, negative_train_history_data, negative_test_history_data, target_idx_list"
      ],
      "metadata": {
        "id": "IcfrqRhTpRjA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XCUDD40abE7"
      },
      "source": [
        "### load_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aI60FdsB5B7y"
      },
      "outputs": [],
      "source": [
        "def load_all(train_history_data, test_history, user_num, item_num):\n",
        "\t\"\"\" We load all the three file here to save time in each epoch. \"\"\"\n",
        "\tprint(f\"load all 속 {user_num}, {item_num}\")\n",
        "\n",
        "\ttrain_data = []\n",
        "\tfor user_idx, visited_list in enumerate(train_history_data):\n",
        "\t\tfor b_id in visited_list:\n",
        "\t\t\ttrain_data.append([user_idx, b_id])\n",
        "\n",
        "\t# load ratings as a dok matrix\n",
        "\t# ratings를 dok(Dictionary of Keys, 좌표:key, 원소 값: value) 형식의 sparse matrix로 변환\n",
        "\ttrain_mat = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
        "\tfor x in train_data:\n",
        "\t\ttrain_mat[x[0], x[1]] = 1.0\n",
        "\n",
        "\t# test_rating 파일을 읽어 test_data로 로드\n",
        "\ttest_data = []\n",
        "\tfor user_idx, visited_list in enumerate(test_history):\n",
        "\t\tfor b_id in visited_list:\n",
        "\t\t\ttest_data.append([user_idx, b_id])\n",
        "\n",
        "\treturn train_data, test_data, train_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "345MEVGKGu9c"
      },
      "source": [
        "## Distance_prob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Haversine 거리 계산 함수\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    r = 6371  # 지구 반지름 (km)\n",
        "    return c * r\n",
        "\n",
        "def distance_prob_check(x):\n",
        "  a, b = 0.02059073981980995 , -2.4172468185424805\n",
        "  if x == 0.0:\n",
        "    return 0\n",
        "  y = a * (x**b)\n",
        "\n",
        "  if y>1:\n",
        "    y = 1\n",
        "  return y"
      ],
      "metadata": {
        "id": "-PQOQe7ppxdU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YzlTEW0GwqQ",
        "outputId": "706a2e5e-0038-4a06-b446-4aefa3b044fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 0.5062683477350807, 1, 0.004364020392940585, 1, 1, 1, 0.6434971353677158, 1, 0.03649965115955932, 0.25666259965085203, 0.5932454964259025, 1, 0.3973781762991897, 0.028821709346761943, 0.026426402202928263, 1, 0.037712817533305854, 0.2493088265350592, 1, 1, 1, 0.41772708235931927, 1, 0.06682949966145417, 1, 0.024737515091624602, 1, 1, 1, 0.013533013561494996, 0.5150062031186471, 0.011953154978114569, 1, 0.08271545887236129, 1, 0.1964851353020116, 0.008625643283514348, 0.10217434901306069, 0.06538186218425203, 0.049018794151038866, 1, 1, 0.2575239276251131, 1, 0.2575239276251131, 0.558134266998659, 0.10432556243219912, 0.05605453152935245, 0.4215041237990345, 1, 0.6145118480268044, 1, 1, 1, 0.26009510078500403, 1, 1, 0.5589525772049392, 0.5096942803782982, 1, 0.08159350457236914, 1, 0.1619210042501226, 0.563066553260938, 0.014119771373554895, 1, 1, 0.013626608381887458, 0.22617371603495623, 1, 0.31214135989589914, 1, 0.2075139540148934, 0.7593254273731245, 1, 1, 0.0832121807179334, 0.4628608969623677, 0.15573108708049854, 1, 0.05068007982665148, 0.5483381782124155, 0.8925587271067643, 0.9837741026379572, 1, 1, 1, 0.12149210167727387, 0.08585045792960505, 0.04446193561165302, 1, 1, 0.31706409009701014, 1, 0.6265331456222928, 1, 0.8184259717514136, 0.7593254273731245, 1, 1, 1, 0.2450624028861446, 0.43334898985559195, 0.14668266619728226, 1, 1, 0.2296956376357537, 0.1260265750601559, 1, 0.28861369149133403, 1, 0.04401917518974237, 0.06190395649249738, 0.9975399413243792, 1, 0.006159740554781595, 0.303443603248911, 0.031646814336612365, 0.37412049303222566, 0.0987157252269407, 0.061394468774415456, 0.004463768802461331, 0.13167823009887164, 1, 1, 1, 0.607649284038748, 1, 1, 0.027182394386734227, 0.10217434901306069, 1, 0.037536217473497224, 0.6958324698754269, 0.06190395649249738, 0.4863893896694117, 1, 0.07679746388377749, 1, 0.4348224832943687, 0.09328382990477281, 0.04106182583701992, 1, 0.08161641939373106, 1, 1, 1, 0.10550924618299479, 1, 0.020736439470857588, 1, 0.038003621954024916, 1, 0.6376996720687833, 1, 1, 1, 0.4803305788954759, 0.7705150073038954, 0.10417360241545048, 1, 1, 0.25796388035474666, 1, 0.0684265183545437, 0.10262355887515529, 1, 1, 0.012091432334504975, 0.4998110331527325, 0.0920231677832862, 1, 1, 0.025171779908620982, 0.8098329759336905, 0.23981027047992512, 1, 1, 1, 0.054798387769938284, 0.1851472900838625, 0.010869760622651228, 1, 0.29362096775833524, 0.9724360081573469, 1, 0.1199093959216055, 0.08159350457236914, 0.09274137962637902, 0.13739453808203053, 0.0724936396083213, 0.681528458504134, 0.010102483450452221, 0.11580234409493986, 1, 0.30729427599535913, 1, 0.4176413311901833, 0.0724936396083213, 0.022553964647466316, 0.5325173217897098, 0.6498905561577704, 1, 1, 0.9246257928376593, 0.0330645766205976, 1, 1, 0.019266189525917975, 1, 0.125049492738827, 0.9030351172260862, 0.13280147819264265, 1, 0.004219042939289506, 0.9594648232625714, 0.682943384180265, 1, 0.7243552232539725, 1, 0.013862092202795164, 0.09706921876062957, 0.3229540795735412, 1, 0.20166018384413475, 1, 0.0075742627325617404, 0.23115488614833463, 1, 0.04401917518974237, 1, 0.7111126214044629, 0.1741352810967967, 0.2939185546744768, 1, 0.4165611340817284, 1, 0.5544767570662908, 1, 1, 1, 1, 0.3979796650292064, 0.12503405267145834, 0.41239074882090804, 0.4794484693921171, 1, 1, 1, 0.3725583892745578, 1, 0.31408565700250785, 1, 0.8005975791132549, 0.6883507851293756, 1, 1, 0.04081696600752514, 0.4192554901663262, 1, 1, 1, 1, 0.9319308559564993, 0.33768352965468484, 1, 1, 1, 0.396029870193679, 1, 1, 1, 1, 1, 0.20166018384413475, 0.1187207792490756, 0.44857012177355726, 1, 0.009745616981578156, 1, 0.5573460368812114, 1, 0.2809502569957741, 1, 0.2614661255984554, 1, 0.6491487952562962, 0.29845646887784777, 0.12968768037758638, 1, 0.13762134468198428, 1, 0.7246362985453169, 0.06029574580119421, 0.03612509802287104, 1, 0.6220712421403467, 0.01400541388222707, 1, 0.15663981687102227, 0.0524749014109732, 1, 0.022633833408513177, 0.09815347304912117, 0.7698072294800342, 0.013039906622334537, 1, 1, 0.14663446493056517, 0.025259663567736568, 1, 0.13445699868396466, 1, 0.0011909944924997453, 1, 1, 0.1164326148421027, 0.5494350450768345, 0.01865113947951909, 0.28115886421975933, 0.29886471017674765, 1, 1, 1, 1, 0.05475124959834414, 0.18195702415655748, 0.7970202504573637, 0.13739453808203053, 0.4052499212093488, 0.022488429081660488, 0.9079219030932856, 0.138501058919341, 0.22622720697590334, 0.3222580775905859, 0.32449082607510565, 0.12127943876382748, 0.08834003816302544, 1, 0.22145399266975224, 0.799596494612795, 0.4221072057152027, 0.2549220193629016, 0.17622900787203602, 0.07103593023538692, 1, 0.08804090821902891, 1, 0.5268425043160608, 1, 1, 0.2327490655171761, 0.09328382990477281, 0.11178228975212764, 0.6752541916134408, 1, 0.5578360652739653, 0.023418062286245808, 0.01726617053101044, 0.44005576739107766, 1, 0.10090075988460999, 0.44857012177355726, 0.12149210167727387, 0.13189818430985675, 1, 0.48989193816849014, 0.13108856006778513, 0.1517500783194578, 0.6570655776604524, 1, 1, 1, 1, 1, 1, 0.2851001198608336, 0.011281141604497827, 0.125049492738827, 0.01147834219105955, 1, 0.4106384509477152, 0.8792677035458349, 1, 0.657348267242387, 0.31214135989589914, 1, 0.7857715688026559, 0.04164332208909898, 0.7026818136001456, 0.7816749639059422, 0.48488718209014514, 0.27597173816069975, 1, 0.2985744397644167, 1, 0.469802671999626, 1, 0.028848220522971094, 1, 1, 0.8005975791132549, 1, 0.7111126214044629, 0.03785516831415069, 0.3193657830450706, 1, 0.21417350525558182, 0.015562633332466026, 1, 0.5345057813817397, 0.3089156975237541, 0.11178228975212764, 0.15573108708049854, 1, 0.266204489209152, 1, 1, 1, 0.04913777536691493, 0.3916064752223296, 0.41853624276518625, 0.1029925120390848, 1, 0.22145399266975224, 0.18551007861864224, 1, 1, 1, 0.13108856006778513, 1, 0.054883342636734826, 0.042338491607722475, 0.5581368673110231, 0.32123986964484536, 1, 0.08585045792960505, 0.5544767570662908, 0.24508641147847635, 0.12721666191050088, 1, 0.13912820762754374, 1, 0.13461873671377247, 1, 0.09187360617544182, 0.04971128091282735, 1, 0.03742387984391106, 0.6112919884200797, 0.08161641939373106, 1, 1, 0.28115886421975933, 0.3830434013252879, 0.3203987952867246, 0.04081696600752514, 0.3489936418654598, 0.22050518561835342, 1, 1, 0.6160860252784356, 1, 0.43334898985559195, 1, 0.5062683477350807, 0.06255629956583467, 0.16398122503773843, 0.021786478554163692, 0.15581325562371323, 0.026208781999384145, 1, 1, 1, 0.6784027593234118, 1, 0.11128224620048369, 0.02558141674918725, 0.08526955465454236, 1, 0.06538186218425203, 1, 0.6060485937725687, 1, 1, 0.32619573088486836, 1, 1, 0.45626771330636, 0.5961228911670353, 1, 1, 0.01659933184375425, 0.5358364854010461, 0.09874902519190953, 1, 1, 0.013544518630381286, 0.6783815213198994, 1, 1, 1, 0.22639860568806405, 1, 1, 1, 0.009973520016800384, 0.8794311624817556, 0.1332977760450396, 0.3859050337750012, 1, 0.8794311624817556, 0.46603044106681935, 0.04332415971600221, 0.29122951884534487, 1, 1, 0.04496301896365949, 1, 1, 1, 1, 1, 1, 1, 0.29061064447121526, 0.05527588627796979, 1, 1, 1, 0.10139506018540537, 1, 0.5910546721459083, 0.7623749674009868, 0.038074030618109225, 1, 0.03825791417313542, 1, 0.011670020555747843, 1, 0.4192554901663262, 1, 1, 1, 0.563066553260938, 1, 0.28861369149133403, 1, 1, 0.0027662060619306913, 1, 1, 0.4629161832308303, 1, 0.4215041237990345, 1, 1, 0.41939836527052926, 1, 1, 0.38589183079368133, 0.05589722289961604, 0.642359864848775, 0.0149315596232073, 0.10348277408075371, 0.6642603451692471, 1, 0.07182592288965232, 0.07182592288965232, 1, 0.37844584768369105, 0.012948392826654288, 1, 0.3516945584144112, 1, 1, 1, 0.0842509732723155, 0.5183972098848538, 0.9246257928376593, 0.20166018384413475, 1, 0.15404595489273215, 1, 1, 0.15712281051315724, 0.025889684806144102, 0.8792677035458349, 0.09986754583663286, 1, 1, 0.31706409009701014, 0.6588432070706922, 0.31319298628473113, 0.006998417184821675, 1, 0.04739347124457463, 1, 0.11260502321674007, 0.008625643283514348, 0.41239074882090804, 0.012308237901729486, 0.021735620981732314, 1, 1, 1, 1, 0.44755025924345376, 0.4192554901663262, 1, 0.4410747696052503, 0.30687065522698764, 0.01775961590623059, 1, 1, 1, 1, 1, 0.04245306199890757, 1, 1, 0.011884122790345997, 1, 1, 0.29061064447121526, 1, 1, 1, 0.4794484693921171, 1, 1, 0.02903990619221829, 0.21407690409386104, 1, 1, 0.8684119266163474, 0.024722810430585246, 0.2501763117518679, 0.46603044106681935, 1, 0.03990789393686451, 0.5565333263855015, 0.08804090821902891, 0.3790794699201868, 0.32359953976979133, 0.2614661255984554, 1, 1, 0.3859050337750012, 1, 0.1008165809893649, 0.02064865144418461, 0.1171862702072697, 0.41772708235931927, 1, 1, 0.48488718209014514, 0.0842509732723155, 0.008617609750130664, 0.03922561832645857, 0.03558496560142873, 0.04030052396078396, 1, 1, 1, 0.10445200386727116, 1, 0.11128224620048369, 0.014670118764659686, 0.7772544953511263, 1, 1, 1, 0.5573460368812114, 0.3797526312482577, 1, 1, 0.657348267242387, 0.028821709346761943, 1, 0.01726617053101044, 0.05541165627915498, 1, 0.007782159036650603, 1, 1, 0.6988212518505056, 0.42805431152403717, 1, 0.896040072950574, 0.13445699868396466, 0.3203987952867246, 0.5268425043160608, 0.008281492808121897, 0.005398584885473018, 0.051618292818510346, 0.5150062031186471, 0.11688676936674249, 0.18256287781707414, 0.8680221181110779, 1, 0.4112021633475647, 1, 1, 1, 1, 0.22050518561835342, 0.9680793779010773, 0.0013180280138155248, 1, 0.10139506018540537, 1, 0.9030351172260862, 0.056233301957517814, 0.08834003816302544, 1, 0.056233301957517814, 0.28452991468895167, 1, 1, 0.558134266998659, 0.04088232989697231, 0.08996373560921957, 0.020736439470857588, 1, 0.6520610377461822, 0.006159740554781595, 0.3485630448123663, 1, 0.06720054148316608, 1, 1, 0.2346530400026365, 0.7483684194279883, 1, 0.5096942803782982, 0.8925587271067643, 0.30729427599535913, 0.014670118764659686, 1, 0.44960449630917537, 0.025887308237711817, 0.11139959150995739, 1, 1, 0.4144497860458807, 0.02126310159198495, 0.19115160154848135, 1, 0.0331369947098973, 1, 1, 0.004858409483285471, 1, 1, 1, 0.05755366410253503, 1, 0.30522327312082037, 0.11580234409493986, 1, 0.39982460218708304, 1, 1, 1, 0.29798169678313896, 0.015562633332466026, 0.6160860252784356, 0.29187636272054296, 0.05068007982665148, 0.0832830814941091, 0.0832121807179334, 0.30687065522698764, 0.6883507851293756, 0.48989193816849014, 1, 1, 1, 0.0071317702056056835, 0.3485630448123663, 0.21081770252743942, 0.038003621954024916, 1, 0.0920231677832862, 1, 1, 1, 1, 0.4348224832943687, 0.2342357129218441, 1, 0.30687065522698764, 0.17622900787203602, 0.31488330375256673, 1, 1, 0.15404595489273215, 0.31388931840075884, 0.49553358715469165, 0.028848220522971094, 1, 1, 0.9149919089538252, 1, 1, 0.003452690766605447, 0.27597173816069975, 0.6414673108122517, 0.3973781762991897, 1, 0.08342687481589872, 1, 0.03785516831415069, 0.2260422117940156, 1, 0.01750332037602194, 0.504064029752997, 0.06934330215733878, 1, 1, 1, 1, 0.15609483212987826, 1, 1, 1, 0.1349935129803008, 0.05041968227737414, 1, 1, 1, 1, 0.1767686464387739, 0.8122837847410871, 1, 1, 0.8184259717514136, 0.4556371888637311, 1, 1, 0.6883507851293756, 1, 0.4086593900949615, 0.870274365214741, 1, 0.23949617751132435, 1, 0.9975399413243792, 1, 1, 0.012308237901729486, 1, 0.9149919089538252, 0.01227137047381206, 0.595642185126267, 0.08264984909009396, 0.02513668584731459, 1, 1, 1, 0.005617418340446088, 1, 0.266204489209152, 1, 0.13167823009887164, 1, 1, 0.39629517854092033, 0.1854068783752097, 1, 0.1133489942039957, 0.06720054148316608, 1, 0.7026818136001456, 0.13308197462986104, 1, 1, 0.42805431152403717, 0.05667645081751297, 0.3673924412115295, 1, 0.32449082607510565, 0.024722810430585246, 0.13632844509919873, 1, 0.303443603248911, 1, 0.7772544953511263, 0.10217434901306069, 0.4200675244042345, 1, 0.039239790217201996, 0.21081770252743942, 0.7175927233943827, 0.28633828742694906, 0.0065828714232539194, 1, 1, 1, 0.10097318278040385, 1, 0.13304164269173616, 0.6069955760868446, 1, 0.46804039500073935, 0.06511195149188184, 1, 1, 1, 0.013601005309705375, 0.469802671999626, 1, 0.030429063967581403, 0.030616527419538415, 1, 0.5736594764054802, 0.021735620981732314, 1, 1, 1, 0.8052244461974752, 0.08896551361861166, 0.21417350525558182, 0.37412049303222566, 1, 0.1576397724538676, 1, 1, 0.5345057813817397, 0.0149315596232073, 0.870274365214741, 1, 0.06469224594809486, 1, 1, 0.5082771239130618, 0.2346530400026365, 1, 0.34165829820254273, 0.3058602648661673, 1, 0.013758520899927249, 1, 0.014316517596892769, 0.642699633912365, 1, 0.09953937329985078, 1, 1, 0.7705150073038954, 0.3535419484708293, 0.682943384180265, 0.0792722215406504, 1, 1, 0.10217434901306069, 0.13353838814286245, 0.04913777536691493, 0.07328428474798536, 0.05041968227737414, 0.9983489052926895, 0.9724360081573469, 1, 1, 0.13912820762754374, 0.0524749014109732, 0.5565333263855015, 0.21007577849415032, 0.011281141604497827, 1, 0.8875278772698628, 0.29886471017674765, 0.02308778060556841, 1, 1, 0.868328409453917, 0.9837741026379572, 1, 0.02116170610815666, 0.007782159036650603, 0.6458080174754828, 0.3345197918487262, 0.7175927233943827, 0.29187636272054296, 0.0219624132842722, 1, 1, 0.8300436815090477, 1, 0.6713809946150175, 1, 1, 0.03727808267920666, 1, 0.799596494612795, 0.24674343893532405, 0.18195702415655748, 0.18551007861864224, 1, 0.1255580872313468, 1, 0.4221072057152027, 0.44005576739107766, 0.7682470582060597, 1, 1, 1, 0.31488330375256673, 1, 0.009270104741399008, 1, 1, 0.005433163031064666, 0.013188161667040708, 0.588741930406067, 1, 0.4981484420417985, 1, 1, 1, 1, 0.3438315995018908, 0.7970202504573637, 0.08264984909009396, 1, 1, 0.011884122790345997, 0.5581368673110231, 0.3916064752223296, 0.2493088265350592, 1, 1, 0.0021041948443799815, 1, 0.15673724233913117, 1, 1, 1, 1, 1, 0.04401917518974237, 0.06410248665784268, 0.588741930406067, 0.030669186883762512, 0.17571755582053117, 1, 0.8960577871288982, 1, 0.30476571505868466, 0.8098329759336905, 1, 0.20788137917479518, 1, 1, 0.2549220193629016, 0.009701518525602039, 1, 1, 0.3345197918487262, 1, 1, 1, 1, 0.29567033325185216, 1, 0.4434388885338315, 0.6042815463436161, 1, 0.4221072057152027, 0.38589183079368133, 1, 0.09624286375144443, 0.011953154978114569, 1, 0.02130887118945967, 0.88814449200939, 0.015619990208522868, 1, 1, 0.6883507851293756, 1, 0.052487117113275736, 1, 0.03853204804332087, 1, 1, 1, 0.11260502321674007, 0.007182395804258029, 0.05781360721426969, 1, 0.396029870193679, 0.0070576752092945, 0.04525080266993971, 1, 1, 0.07261544858717527, 1, 0.07328428474798536, 1, 0.1398627215632971, 1, 0.817997690718261, 1, 0.28573999327234395, 0.001438877840117526, 0.9594648232625714, 1, 0.10612849449433429, 1, 1, 0.3222580775905859, 0.3438315995018908, 0.04245306199890757, 1, 0.29200845179910906, 0.24674343893532405, 1, 0.3887347186288277, 1, 0.20167366202987147, 1, 1, 1, 0.5910546721459083, 1, 0.4192554901663262, 1, 0.14000410631768875, 1, 1, 0.642699633912365, 1, 1, 0.6783815213198994, 1, 1, 1, 1, 0.20167366202987147, 0.017287159811994936, 0.88814449200939, 0.2866790813446497, 1, 0.0795398348612227, 0.41939480912178484, 1, 1, 1, 0.16421131171786438, 0.3489936418654598, 0.01414605598680011, 0.7671139573699007, 1, 0.03570046430709989, 1, 0.18551007861864224, 1, 0.21381445309513403, 1, 0.22639860568806405, 0.3797526312482577, 0.1915375439317956, 0.20788137917479518, 1, 1, 1, 0.24637841403201505, 0.08996373560921957, 1, 1, 0.2825710899296924, 1, 0.6434971353677158, 1, 1, 0.3725583892745578, 1, 1, 1, 0.146793367333288, 0.1964124072742779, 0.054798387769938284, 0.32123986964484536, 0.6069955760868446, 0.2664862778743476, 0.8052244461974752, 1, 0.2912769737647141, 0.016057581906020316, 0.04496301896365949, 0.03641163723168154, 0.20188074492397487, 1, 1, 0.006359483224343023, 1, 1, 0.01659933184375425, 0.8251127602914285, 0.06949054517098285, 1, 0.0276015625380338, 1, 0.7380763933830874, 0.4801665144263281, 0.0817411100322611, 1, 0.047933634644384285, 0.06255629956583467, 0.06934330215733878, 0.0837435276893011, 0.19774990342760643, 0.3887347186288277, 0.9983489052926895, 0.12503405267145834, 0.6520610377461822, 0.5268425043160608, 1, 1, 1, 0.047933634644384285, 0.10217434901306069, 0.1285268582095251, 0.5168860107897201, 0.0331369947098973, 1, 0.531340149340808, 1, 0.08896551361861166, 1, 1, 0.5589525772049392, 0.007355253930140558, 1, 0.1468686785688872, 0.6060485937725687, 0.6458080174754828, 1, 0.008281492808121897, 0.13459350124158323, 0.26009510078500403, 0.03622366866511683, 0.02450927732572458, 1, 0.10432556243219912, 0.28181607502531053, 1, 1, 1, 0.02429251536965929, 1, 1, 0.2937640885507249, 0.12721666191050088, 1, 0.13461873671377247, 0.1722347727519745, 1, 1, 1, 0.1468686785688872, 0.18256287781707414, 1, 1, 0.012596287600468435, 1, 0.4702932489194406, 0.29868576312789985, 1, 1, 1, 0.12798955251719046, 0.2396643895836702, 0.25280124915830077, 1, 1, 1, 1, 1, 1, 1, 0.14000410631768875, 1]\n"
          ]
        }
      ],
      "source": [
        "def distance_prob(target_idx_list, lat_list, long_list):\n",
        "  distance_prob_list = []\n",
        "  for user, visit_list in enumerate(target_idx_list):\n",
        "    user_prob_list = []\n",
        "    for b_id in visit_list:\n",
        "      min_dist = 9999\n",
        "      lat1 = lat_list[b_id]\n",
        "      long1 = long_list[b_id]\n",
        "      for comp_b_id in visit_list:\n",
        "        if b_id == comp_b_id:\n",
        "          continue\n",
        "        lat2 = lat_list[comp_b_id]\n",
        "        long2 = long_list[comp_b_id]\n",
        "        dist = haversine(lat1, long1, lat2, long2)\n",
        "        if min_dist > dist:\n",
        "          min_dist = dist\n",
        "      prob = distance_prob_check(min_dist)\n",
        "      user_prob_list.append(prob)\n",
        "  distance_prob_list.append(user_prob_list)\n",
        "  return distance_prob_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdM-wlnuaYLO"
      },
      "source": [
        "### BPRData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XnmANPppyCqB"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 클래스 정의\n",
        "class BPRData(data.Dataset):\n",
        "\tdef __init__(self, features,\n",
        "\t\t\t\tnum_item, train_mat=None, num_ng=0, is_training=None, ng_dataset = None):\n",
        "\t\tsuper(BPRData, self).__init__()\n",
        "\t\t\"\"\"\n",
        "\t\t\tNote that the labels are only useful when training, we thus\n",
        "\t\t\tadd them in the ng_sample() function.\n",
        "\t\t\"\"\"\n",
        "\t\tself.features = features #training, test dataset\n",
        "\t\tself.num_item = num_item\n",
        "\t\tself.train_mat = train_mat\n",
        "\t\tself.num_ng = num_ng\n",
        "\t\tself.is_training = is_training\n",
        "\t\tself.ng_dataset = ng_dataset\n",
        "\n",
        "\tdef ng_sample(self):\n",
        "\t\tassert self.is_training, 'no need to sampling when testing'\n",
        "\t\t#훈련 데이터셋에 대하여 Negativesample 만듦\n",
        "\t\tself.features_fill = []\n",
        "\t\tfor x in self.features: # training_dataset에 있는 positive data에 랜덤한 negative data를 생성해 매치해줌\n",
        "\t\t\tu, i = x[0], x[1]\n",
        "\n",
        "\t\t\tfor t in range(self.num_ng):\n",
        "\t\t\t\tj = np.random.randint(0, self.num_item) # num_items == len(item_list), item_list에서 Negative sample을 골라야하기 때문에 인덱스를 골라줌\n",
        "\t\t\t\tng_data = self.ng_dataset[u]\n",
        "\t\t\t\tsampled_indices = random.sample(range(len(ng_data)-1), self.num_ng)\n",
        "\t\t\t\tfor idx in sampled_indices:\n",
        "\t\t\t\t\tj = int(ng_data[idx])\n",
        "\t\t\t\t\tself.features_fill.append([u, i, j])\n",
        "\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn self.num_ng * len(self.features) if \\\n",
        "\t\t\t\tself.is_training else len(self.features)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tfeatures = self.features_fill if \\\n",
        "\t\t\t\tself.is_training else self.features\n",
        "\n",
        "\t\tuser = features[idx][0]\n",
        "\t\titem_i = features[idx][1]\n",
        "\t\titem_j = features[idx][2] if \\\n",
        "\t\t\t\tself.is_training else features[idx][1]\n",
        "\n",
        "\t\treturn user, item_i, item_j\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlziZaQAyHs_"
      },
      "source": [
        "# MFbpr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "go6iy9RtgO0Y"
      },
      "outputs": [],
      "source": [
        "class BPR(nn.Module):\n",
        "\tdef __init__(self, user_num, item_num, factor_num):\n",
        "\t\tsuper(BPR, self).__init__()\n",
        "\t\t\"\"\"\n",
        "\t\tuser_num: 사용자 수\n",
        "\t\titem_num: 아이템 수\n",
        "\t\tfactor_num: 예측할 factors의 수\n",
        "\t\t\"\"\"\n",
        "\t\t # 사용자와 아이템을 factor 수 만큼 임베딩하는 레이어를 생성\n",
        "\t\tself.embed_user = nn.Embedding(user_num, factor_num)\n",
        "\t\tself.embed_item = nn.Embedding(item_num, factor_num)\n",
        "\n",
        "\t\t# 임베딩 레이어의 가중치를 정규 분포에서 초기화한다.\n",
        "\t\tnn.init.normal_(self.embed_user.weight, std=0.01)\n",
        "\t\tnn.init.normal_(self.embed_item.weight, std=0.01)\n",
        "\n",
        "\tdef forward(self, user, item_i, item_j):\n",
        "\t\t\"\"\"\n",
        "        Parameters:\n",
        "            user (torch.Tensor): 사용자 ID list\n",
        "            item_i (torch.Tensor): positive 아이템 list\n",
        "            item_j (torch.Tensor): negative 아이템 list\n",
        "        Returns:\n",
        "            torch.Tensor: 긍정적인 아이템에 대한 예측 값\n",
        "            torch.Tensor: 부정적인 아이템에 대한 예측 값\n",
        "\t\t\"\"\"\n",
        "\t\tuser = self.embed_user(user)\n",
        "\t\titem_i = self.embed_item(item_i)\n",
        "\t\titem_j = self.embed_item(item_j)\n",
        "\n",
        "\t\tprediction_i = (user * item_i).sum(dim=-1)  # user * i matrix 생성\n",
        "\t\tprediction_j = (user * item_j).sum(dim=-1) # user * j matrix 생성\n",
        "\n",
        "\t\treturn prediction_i, prediction_j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp7sPx2MyNGw"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JZ6f1k4Yqxnx"
      },
      "outputs": [],
      "source": [
        "def eval(model, num_users, testPositives, target_idx_list, target_idx_dist_prob_list):\n",
        "\tmodel.eval()\n",
        "\thit = [0,0,0,0,0]\n",
        "\tprecision = [0,0,0,0,0]\n",
        "\trecall = [0,0,0,0,0]\n",
        "\n",
        "\tk=[10,20,30,40,50]\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\tfor u in range(num_users):\n",
        "\t\t\ttarget_idx = target_idx_list[u]\n",
        "\t\t\tuser_list = [u] * len(target_idx)\n",
        "\t\t\tuser_tensor = torch.tensor(user_list)\n",
        "\t\t\ttarget_tensor = torch.tensor(target_idx)\n",
        "\t\t\tdist_tensor = torch.tensor(target_idx_dist_prob_list[u])\n",
        "\n",
        "\t\t\tprediction_i, prediction_j = model(user_tensor, target_tensor, target_tensor)\n",
        "\n",
        "\t\t\tprint(f\"prediction_i : {prediction_i.shape}\")\n",
        "      #각각의 유저에 대해서 target_idx에 있는 가게 거리 정보를 더해줘야함\n",
        "\n",
        "\n",
        "\t\t\t#print(f\"dist_prob : {dist_tensor}\")\n",
        "\t\t\talpha = 0.7\n",
        "\t\t\tprediction_i = alpha * prediction_i + (1 - alpha) * dist_tensor\n",
        "\n",
        "\t\t\tfor i in range(len(k)):\n",
        "\t\t\t\t_, indices = torch.topk(prediction_i, k[i])\n",
        "\t\t\t\trecommends = [target_idx[i] for i in indices]\n",
        "\t\t\t\ttopSet = set(recommends)\n",
        "\n",
        "\t\t\t\tpositives = set(testPositives[u])\n",
        "\t\t\t\tcount = len(topSet & positives)\n",
        "\n",
        "\t\t\t\tprecision[i] += (count/k[i]) / num_users\n",
        "\t\t\t\trecall[i] += (count/len(testPositives[u]))/ num_users\n",
        "\t\t\t\tif count >0:\n",
        "\t\t\t\t\thit[i] += 1/ num_users\n",
        "\n",
        "\treturn recall , precision, hit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZudji07yM-B"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "49YUXtKqyFvl",
        "outputId": "ad151069-c6f4-4a23-d7f0-e1a388b3b8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15360 14586\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([4096])\n",
            "torch.Size([464])\n",
            "prediction_i : torch.Size([20])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-7d386b94b21d>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 모델을 평가 모드로 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mrecall\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_history_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_history_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_idx_list_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mavg_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-cc066ef8b5e6>\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, num_users, testPositives, history_list, target_idx_list)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                                 \u001b[0mrecommends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                 \u001b[0mtopSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
          ]
        }
      ],
      "source": [
        "\"\"\"#Main\"\"\"\n",
        "class Args:\n",
        "\tdef __init__(self):\n",
        "\t\tself.lr = 0.01 # learning rate\n",
        "\t\tself.lamda = 0.001 # model regularization rate\n",
        "\t\tself.batch_size = 4096 # batch size for training\n",
        "\t\tself.epochs = 25 # training epoches\n",
        "\t\tself.top_k = 10 # compute metrics@top_k\n",
        "\t\tself.factor_num = 32 # predictive factors numbers in the modelㄹ\n",
        "\t\tself.num_ng = 4 # sample negative items for training\n",
        "\t\tself.test_num_ng = 99 # sample part of negative items for testing\n",
        "\t\tself.out = True # save model or not\n",
        "\t\t#self.gpu = \"0\" # gpu card ID\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\targs = Args()\n",
        "\n",
        "\titem_list, latitude_list, longitude_list, num_users, num_items, train_history_data, validation_history_data, test_history_data, negative_train_history_data, \\\n",
        "\tnegative_test_history_data, target_idx_list_for_test = load_data()\n",
        "\n",
        "\t############################## PREPARE DATASET ##########################\n",
        "\ttrain_data, test_data, train_mat = load_all(train_history_data, test_history_data, num_users, num_items)\n",
        "\ttarget_idx_dist_prob_list = distance_prob(target_idx_list_for_test, latitude_list, longitude_list)\n",
        "\n",
        "\n",
        "\t# construct the train and test datasets\n",
        "\t# 훈련 및 테스트 데이터셋 생성\n",
        "\ttrain_dataset = BPRData(\n",
        "\t\t\ttrain_data, num_items, train_mat, args.num_ng, True, negative_train_history_data)\n",
        "\n",
        "\ttest_dataset = BPRData(\n",
        "\t\t\ttest_data, num_items, train_mat, 0, False)\n",
        "\n",
        "\t# DataLoader로 배치 처리를 위한 데이터 로더 생성\n",
        "\ttrain_loader = data.DataLoader(train_dataset,\n",
        "\t\t\tbatch_size=args.batch_size, shuffle=True, num_workers=0)  # num_workers를 0으로 변경하여 CPU에서 처리, 기존 코드는 GPU를 사용\n",
        "\ttest_loader = data.DataLoader(test_dataset,\n",
        "\t\t\tbatch_size=args.test_num_ng+1, shuffle=False, num_workers=0)\n",
        "\n",
        "\t########################### CREATE MODEL #################################\n",
        "\t# BPR 모델 생성\n",
        "\tmodel = BPR(num_users, num_items, args.factor_num)\n",
        "\n",
        "\t# 옵티마이저 생성 (SGD 사용)\n",
        "\toptimizer = optim.SGD(\n",
        "\t\t\t\tmodel.parameters(), lr=args.lr, weight_decay=args.lamda)\n",
        "\t# writer = SummaryWriter() # for visualization\n",
        "\n",
        "\t########################### TRAINING #####################################\n",
        "\tcount, best_hr = 0, 0\n",
        "\n",
        "\tavg_recall = [0, 0, 0, 0, 0]\n",
        "\tavg_precision = [0, 0, 0, 0, 0]\n",
        "\tavg_hit = [0, 0, 0, 0, 0]\n",
        "\tfor epoch in range(args.epochs):\n",
        "\t\tmodel.train()  # 모델을 학습 모드로 설정\n",
        "\t\tstart_time = time.time() # 시작시간 기록\n",
        "\t\tnum = 0\n",
        "\t\ttrain_loader.dataset.ng_sample() # negative 예제 샘플링\n",
        "\t\tfor user, item_i, item_j in train_loader:\n",
        "\t\t\tmodel.zero_grad() # 그래디언트 초기화\n",
        "\t\t\tprediction_i, prediction_j = model(user, item_i, item_j)\n",
        "\t\t\tloss = - (prediction_i - prediction_j).sigmoid().log().sum() # BPR 손실 함수 계산\n",
        "\t\t\tloss.backward() # 역전파 및 그래디언트 계산\n",
        "\t\t\toptimizer.step() # 옵티마이저 업데이트\n",
        "\t\t\t# writer.add_scalar('data/loss', loss.item(), count)\n",
        "\t\t\tcount += 1\n",
        "\n",
        "\t\tmodel.eval() # 모델을 평가 모드로 설정\n",
        "\t\trecall , precision, hit = eval(model, num_users, test_history_data, target_idx_list_for_test, target_idx_dist_prob_list)\n",
        "\n",
        "\t\tavg_recall = [x + y for x, y in zip(avg_recall, recall)]\n",
        "\t\tavg_precision = [x + y for x, y in zip(avg_precision, precision)]\n",
        "\t\tavg_hit = [x + y for x, y in zip(avg_hit, hit)]\n",
        "\n",
        "\t\telapsed_time = time.time() - start_time  # 소요시간 계산\n",
        "\n",
        "\t\tprint(\"@\" * 30)\n",
        "\t\tprint(\"#\" * 30)\n",
        "\t\tprint(f\"Epoch : {epoch}, Used_Time : {elapsed_time}\")\n",
        "\t\tprint(f\"hit : {hit}\")\n",
        "\t\tprint(f\"precision : {precision}\")\n",
        "\t\tprint(f\"recall : {recall}\")\n",
        "\n",
        "\tfor i in range(5):\n",
        "\t\tprint(\"들어왔다\")\n",
        "\t\tavg_hit[i] /= args.epochs\n",
        "\t\tavg_recall[i] /= args.epochs\n",
        "\t\tavg_precision[i] /= args.epochs\n",
        "\tprint(\"@\" * 30)\n",
        "\tprint(\"#\" * 30)\n",
        "\tprint(\"final\")\n",
        "\tprint(f\"hit : {avg_hit}\")\n",
        "\tprint(f\"precision : {avg_precision}\")\n",
        "\tprint(f\"recall : {avg_recall}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}